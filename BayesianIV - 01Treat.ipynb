{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Treatment and Response\n",
    "\n",
    "In this notebook we are going to outline a method for estimating treatment response models using some Bayesian methods. In this notebook, we will discuss the discrete treatment (i.e., there is a treatment group and a control group like belonging to a union or not), with continuous response (the response we are interested in is a continuous variable, like wages). \n",
    "\n",
    "Why would someone resort to Bayesian methods to estimate this model, as opposed to the classical alternatives such as Instrumental-Variables probit, or even regular linear IV? A couple of reasons:\n",
    "\n",
    "1. Bayesian methods usually have a lot of structure in that the involve a lot of distributional assumptions. Hence, they can be pretty good in small samples. \n",
    "2. Bayesian methods allow one to say something about things like correlation across outcomes that are typically not observable.\n",
    "3. Bayesian methods also generate some things like individual-level treatment effects just as a by-product of estimation.\n",
    "\n",
    "\n",
    "# The basic model and theory\n",
    "\n",
    "We consider a case in which there is a treatment and control group and some set of control variables. In fact, we might think about this more generally as an endogenous switching regression, where agents select into different groups in part based on things we observe about them and maybe on some things we do not. \n",
    "\n",
    "We take treatment to be a dichotomous variable $z = \\{0,1\\}$, and we observe $z=1$ if some underlying latent variable $z^*$, is greater than zero, and $z=0$ otherwise. \n",
    "\n",
    "As a practical matter, we think of the selection-into-treatment equation as a Probit model, where:\n",
    "$$\n",
    "z^* = \\eta W + \\epsilon_z\n",
    "$$\n",
    "And \n",
    "$$ \\begin{array}{ccc}\n",
    "z = 1 & \\textrm{if} & z^* = \\eta W + e_z > 0 \\\\\n",
    "z = 0 & \\textrm{otherwise} &\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Outcome equations differ based on whether or not the individual is treated. If $z=1$, the following equation explains the outcome $y$:\n",
    "$$\n",
    "y_1 = X\\beta_1 + e_1\n",
    "$$\n",
    "and if $z=0$,\n",
    "$$\n",
    "y_0 = X\\beta_0 + e_0\n",
    "$$\n",
    "\n",
    "## Point of interest\n",
    "\n",
    "In observational data, we never actually observe both outcomes for a given individual. I.e., we don't see what happens to a patient if he or she both takes and does not take a medication or we don't see what happens if someone both does and does not join a union. But a Bayesian method allows us to consider this as well - the idea is to treat the unobserved outcome as yet another latent variable that is estimated/simulated along with everything else. \n",
    "\n",
    "The variance matrix for $y_1,y_0$, and $z$ is:\n",
    "\n",
    "$$\n",
    "\\Sigma = \\left[\n",
    "\\begin{array}{ccc}\n",
    "\\sigma_1^2  & \\sigma_{10} & \\sigma_{1z} \\\\\n",
    "                                   & \\sigma_0^2 & \\sigma_{0z} \\\\\n",
    "                                   &      &  1 \n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "We have to also assume that $\\sigma_z=1$ because of the indeterminacy of the scale parameter in a probit model. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods of estimation\n",
    "\n",
    "If we wanted to write the full likelihood of the data, it might consist of three parts: a probit style likelihood describing treatment or not, and then a likelihood for the outcome conditional on treatment. This is tricky in the current setting because we have a trivariate normal distribution, and what can be thought of as two latent variables - the threshold variable for treatment, and the value of whatever is unobserved. This is tough (but not impossible) - Heckman and coauthors have some papers describing methods for dealing with these problems. But my approach will be to think directly about things in terms of a Gibbs sampling approach. \n",
    "\n",
    "### Gibbs sampling\n",
    "\n",
    "To design a Gibbs sampler, one just has to think about the conditional distribution of one thing when everything else is given. Heuristically, my idea is to proceed as follows:\n",
    "\n",
    "1. Given $\\beta,\\eta,\\Sigma, X,y_0$, draw values for $y_1$. That is, draw a treated outcome for those who were not treated (z = 0). \n",
    "2. Given $\\beta,\\eta,\\Sigma, X,y_1$, draw values for $y_0$. That is, draw a non-treated outcome for those who were treated (z=1).\n",
    "3. Given $\\eta,\\Sigma, W,y_0,y_1,z$, draw values for $z^*$, the unobserved latent variable describing selection into treatment.\n",
    "4. Given $\\Sigma, X,y_0,y_1,z$ draw values for $\\beta_0$.\n",
    "5. Given $\\Sigma,X,y_0,y_1,z$ draw values for $\\beta_1$.\n",
    "6. Draw values for the 5 terms in $\\Sigma$.\n",
    "\n",
    "Almost everything here just requires a normal distribution. Number 6 is a little more complicated, but we can use a Markov-chain Monte carlo Metropolis-within-Gibbs step for that. We need one formula, which is that of the conditional normal. If we want to know the distribution of some subset $y_1$ given $y_2$, when mean vectors are $\\mu_1, \\mu_2$ and the variance matrix is $\\Sigma$, we use:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\Sigma = \\left[ \\begin{array}{c|c}\n",
    "\\Sigma_{11} & \\Sigma_{12} \\\\\n",
    "\\hline\n",
    "\\Sigma_{21} & \\Sigma_{22}\n",
    "\\end{array}\\right]\n",
    "\\end{equation*}\n",
    "\n",
    "The conditional mean of $y_1$ given $y_2$ is:\n",
    "\\begin{equation*}\n",
    "E[y_{1|2}] = \\mu_1 + \\Sigma_{12}\\Sigma_{22}^{-1}(y_2 - \\mu_2) \n",
    "\\end{equation*}\n",
    "and the conditional variance of $y_1$ given $y_2$ is:\n",
    "\\begin{equation*}\n",
    "V[y_{1|2}] = \\Sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21} \n",
    "\\end{equation*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:**\n",
    "\n",
    "Use $\\mu_1=X\\beta_1$, $\\mu_2=X\\beta_0, W\\eta$, $y_2=y_0, z$, $\\Sigma_{12} = \\Sigma_{21}' =\\left[\\sigma_{10},\\sigma_{1z}\\right]$,\n",
    "and\n",
    "\\begin{equation*}\n",
    "\\Sigma_{22}=\\left[\\begin{array}{cc}\\sigma_0^2 & \\sigma_{0z} \\\\ \\sigma_{0z} & 1 \\end{array} \\right]\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:**\n",
    "\n",
    "Use $\\m1_0=X\\beta_0$, $\\mu_2=[X\\beta_1,W\\eta]$, $y_2=[y_1, z]$, $\\Sigma_{12} = \\Sigma_{21}' =\\left[\\sigma_{10},\\sigma_{0z}\\right]$,\n",
    "and\n",
    "\\begin{equation*}\n",
    "\\Sigma_{22}=\\left[\\begin{array}{cc}\\sigma_1^2 & \\sigma_{1z} \\\\ \\sigma_{1z} & 1 \\end{array} \\right]\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: **\n",
    "\n",
    "Use $\\mu_1 = W\\eta$, $\\mu_2=[X\\beta_1,X\\beta_0]$, $y_2=[y_1, y_0]$, $\\Sigma_{12} = \\Sigma_{21}' =\\left[\\sigma_{1z},\\sigma_{0z}\\right]$,\n",
    "and\n",
    "\\begin{equation*}\n",
    "\\Sigma_{22}=\\left[\\begin{array}{cc}\\sigma_1^2 & \\sigma_{10} \\\\ \\sigma_{10} & \\sigma_0^2 \\end{array} \\right]\n",
    "\\end{equation*}\n",
    "\n",
    "But note that draws must be from a truncated random normal variable, where if $z=1$, data is left-truncated at 0, and if $z=0$ data is right-truncated at 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 4/5/6: **\n",
    "\n",
    "We now have all the data that we need and all we have to do is transform the dependent variables so that they are purged of cross equation correlation. That is, we remove cross-variable correlation from $y_1,y_0,$ and $z$ and then observe that:\n",
    "\\begin{equation*}\n",
    "\\beta_1 \\sim N\\left[ (X'X)^{-1}X'\\hat{y}_1, \\sigma_{1}^2(X'X)^{-1} \\right]\n",
    "\\end{equation*}\n",
    "Similarly:\n",
    "\\begin{equation*}\n",
    "\\beta_0 \\sim N\\left[ (X'X)^{-1}X'\\hat{y}_0, \\sigma_{0}^2(X'X)^{-1} \\right]\n",
    "\\end{equation*}\n",
    "and finally\n",
    "\\begin{equation*}\n",
    "\\eta \\sim N\\left[ (W'W)^{-1}W'\\hat{z}, (W'W)^{-1}\\right]\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As written, the likelihood above assumes that everything is known. Of course, many things in the problem are not, such as the unobserved outcome and also the actual value of the latent variable $z$. But, in a Bayesian analysis, we just draw these variables along with everything else. Let's consider another `Stata` implementation of this model, where we draw unobserved outcomes along with everything else. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example application - an extended walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we will work with a stock Stata example and use the `ipystata` interface. Here, we use the classic union data set and try to get a feel for the impact of union membership on wages. So, in this case, we have a dichotomous treatment variable with one instrument (in the south). \n",
    "\n",
    "Initially, we are going to take it very slow and worry about how initial draws are produced, and think about how each step works. At the end of this, we are going to write a program to a `.do` file that will speed things up a little bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipystata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(National Longitudinal Survey.  Young Women 14-26 years of age in 1968)\n",
      "(449 observations deleted)\n",
      "(34 observations deleted)\n",
      "\n",
      "Contains data from http://www.stata-press.com/data/r13/union3.dta\n",
      "  obs:         1,210                          National Longitudinal Survey.  Young Women 14-26 years of age in 1968\n",
      " vars:            24                          11 Mar 2013 09:47\n",
      " size:        55,660                          \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "              storage   display    value\n",
      "variable name   type    format     label      variable label\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "idcode          int     %8.0g                 NLS ID\n",
      "year            byte    %8.0g                 interview year\n",
      "birth_yr        byte    %8.0g                 birth year\n",
      "age             byte    %8.0g                 age in current year\n",
      "race            byte    %8.0g      racelbl    race\n",
      "msp             byte    %8.0g                 1 if married, spouse present\n",
      "nev_mar         byte    %8.0g                 1 if never married\n",
      "grade           byte    %8.0g                 current grade completed\n",
      "collgrad        byte    %8.0g                 1 if college graduate\n",
      "not_smsa        byte    %8.0g                 1 if not SMSA\n",
      "c_city          byte    %8.0g                 1 if central city\n",
      "south           byte    %8.0g                 1 if south\n",
      "ind_code        byte    %8.0g                 industry of employment\n",
      "occ_code        byte    %8.0g                 occupation\n",
      "union           byte    %8.0g                 1 if union\n",
      "wks_ue          byte    %8.0g                 weeks unemployed last year\n",
      "ttl_exp         float   %9.0g                 total work experience\n",
      "tenure          float   %9.0g                 job tenure, in years\n",
      "hours           int     %8.0g                 usual hours worked\n",
      "wks_work        int     %8.0g                 weeks worked last year\n",
      "ln_wage         float   %9.0g                 ln(wage/GNP deflator)\n",
      "wage            double  %10.0g                real wage\n",
      "black           float   %9.0g                 race black\n",
      "smsa            byte    %8.0g                 1 if SMSA\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Sorted by: idcode  year\n",
      "     Note: Dataset has changed since last saved.\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "clear all \n",
    "use http://www.stata-press.com/data/r13/union3\n",
    "set more off\n",
    "keep if union != . \n",
    "keep if tenure != .\n",
    "describe \n",
    "set seed 5150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's just fit some preliminary models and get a feel for the problem, to get our bearings and get some ideas as to how large parameters are likely to be:\n",
    "\n",
    "## Simple regression and IV regressions\n",
    "\n",
    "The first thing that we want to do is just run some simple regressions, and a probit for selection into \"treatment\" which is here belonging to a union. In fact, we will take these as the initial values for our Bayesian estimation procedure. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Source |       SS           df       MS      Number of obs   =       253\n",
      "-------------+----------------------------------   F(5, 247)       =     18.89\n",
      "       Model |  419.610641         5  83.9221281   Prob > F        =    0.0000\n",
      "    Residual |  1097.48439       247  4.44325665   R-squared       =    0.2766\n",
      "-------------+----------------------------------   Adj R-squared   =    0.2619\n",
      "       Total |  1517.09503       252  6.02021838   Root MSE        =    2.1079\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "        wage |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         age |   .1562246   .0492065     3.17   0.002     .0593067    .2531425\n",
      "       grade |   .3897226    .062765     6.21   0.000     .2660997    .5133456\n",
      "        smsa |    1.10633   .3384687     3.27   0.001     .4396772    1.772983\n",
      "       black |  -.9184192   .2896539    -3.17   0.002    -1.488926   -.3479126\n",
      "      tenure |   .1521186   .0836497     1.82   0.070    -.0126391    .3168762\n",
      "       _cons |  -2.814175    1.26752    -2.22   0.027    -5.310702   -.3176493\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "      Source |       SS           df       MS      Number of obs   =       957\n",
      "-------------+----------------------------------   F(5, 951)       =     92.69\n",
      "       Model |  1504.87835         5   300.97567   Prob > F        =    0.0000\n",
      "    Residual |  3088.09024       951   3.2472032   R-squared       =    0.3276\n",
      "-------------+----------------------------------   Adj R-squared   =    0.3241\n",
      "       Total |  4592.96859       956  4.80436045   Root MSE        =     1.802\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "        wage |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "         age |   .1452795   .0210829     6.89   0.000      .103905    .1866539\n",
      "       grade |   .4552808   .0335395    13.57   0.000     .3894608    .5211008\n",
      "        smsa |    .954457    .133461     7.15   0.000     .6925449    1.216369\n",
      "       black |  -.5250849   .1390976    -3.77   0.000    -.7980586   -.2521111\n",
      "      tenure |   .2277879   .0367481     6.20   0.000     .1556711    .2999047\n",
      "       _cons |  -4.535484   .5849591    -7.75   0.000    -5.683444   -3.387525\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Iteration 0:   log likelihood = -620.42714  \n",
      "Iteration 1:   log likelihood = -592.34076  \n",
      "Iteration 2:   log likelihood = -592.15539  \n",
      "Iteration 3:   log likelihood = -592.15536  \n",
      "\n",
      "Probit regression                               Number of obs     =      1,210\n",
      "                                                LR chi2(3)        =      56.54\n",
      "                                                Prob > chi2       =     0.0000\n",
      "Log likelihood = -592.15536                     Pseudo R2         =     0.0456\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "       union |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "       south |  -.4895032   .0933276    -5.24   0.000    -.6724221   -.3065844\n",
      "       black |   .4397974   .0972261     4.52   0.000     .2492377    .6303572\n",
      "      tenure |   .0997638   .0236575     4.22   0.000      .053396    .1461317\n",
      "       _cons |  -.9679795   .0746464   -12.97   0.000    -1.114284   -.8216753\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "reg wage age grade smsa black tenure if union == 1\n",
    "mat binit1 = e(b)\n",
    "\n",
    "reg wage age grade smsa black tenure if union == 0\n",
    "mat binit0 = e(b) \n",
    "\n",
    "probit union south black tenure\n",
    "mat einit = e(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we pull all the variables that we need into `Mata`, and some constants to get the full-blown vectors we need, and at the same time, we pull in the initial values from the regressions to be used. We also set logs of variances at zero, and set all covariance terms at 0 too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mata output:\n",
      "\n",
      ":     st_view(y=., ., \"wage\")\n",
      "\n",
      ":     st_view(tr=., ., \"union\")\n",
      "\n",
      ":     st_view(X=., ., \"age grade smsa black tenure\")\n",
      "\n",
      ":     st_view(W=., ., \"south black tenure\")\n",
      "\n",
      ":     X = X, J(rows(y), 1, 1)\n",
      "\n",
      ":     W = W, J(rows(y), 1, 1)\n",
      "\n",
      ":     b0 = st_matrix(\"binit0\")\n",
      "\n",
      ":     e = st_matrix(\"einit\")\n",
      "\n",
      ":     nb = cols(b1)\n",
      "\n",
      ":     ne = cols(e)\n",
      "\n",
      ":     lnsd0 = 0\n",
      "\n",
      ":     v10   = 0\n",
      "\n",
      ":     v1t   = 0\n",
      "\n",
      ":     v0t   = 0\n"
     ]
    }
   ],
   "source": [
    "%%stata --mata\n",
    "    st_view(y=., ., \"wage\")\n",
    "    st_view(tr=., ., \"union\")\n",
    "    st_view(X=., ., \"age grade smsa black tenure\")\n",
    "    st_view(W=., ., \"south black tenure\")\n",
    "    X = X, J(rows(y), 1, 1)\n",
    "    W = W, J(rows(y), 1, 1)\n",
    "\n",
    "    b1 = st_matrix(\"binit1\")\n",
    "    b0 = st_matrix(\"binit0\")\n",
    "    e = st_matrix(\"einit\")\n",
    "    nb = cols(b1)\n",
    "    ne = cols(e)\n",
    "\n",
    "    lnsd1 = 0\n",
    "    lnsd0 = 0\n",
    "    v10   = 0\n",
    "    v1t   = 0\n",
    "    v0t   = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One further thing we need to do is make a more stable inverse-normal function. This is because if a normal probability winds up being either one or zero, the stock invnormal function will return a missing. We don't want this to stop estimation in its tracks! \n",
    "\n",
    "We also create a function that takes error terms $y-\\mu$ and a variance matrix $\\Sigma$, and calculates the joint likelihood of all the data based on these things. It uses a couple of tricks to economize on notation and avoil looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mata output:\n",
      "\n",
      ":     real matrix invnormstab(X) {\n",
      ">         XHat = editvalue(XHat, 1, 1e-16 )\n",
      ">     }\n",
      "\n",
      ":     real scalar ln_L(real matrix errs, real matrix Sigma) {\n",
      ">         part2 = -1/2*colsum(rowsum( (errs*invsym(Sigma):*errs)))\n",
      ">         return(part1 + part2 + part3)\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "command end is unrecognized\n",
      "r(199);\n"
     ]
    }
   ],
   "source": [
    "%%stata --mata\n",
    "    real matrix invnormstab(X) {\n",
    "        XHat = editvalue(X, 0, 1e-323)\n",
    "        XHat = editvalue(XHat, 1, 1e-16 )\n",
    "        return(XHat)\n",
    "    }\n",
    "    real scalar ln_L(real matrix errs, real matrix Sigma) {\n",
    "        part1 = -cols(errs)*rows(errs)/2*ln(2*pi())\n",
    "        part2 = -1/2*colsum(rowsum( (errs*invsym(Sigma):*errs)))\n",
    "        part3 = -rows(errs)/2*ln(det(Sigma))\n",
    "        return(part1 + part2 + part3)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have initial values for all parameters, we now need to fill in some values for the latent $z$, and also for \"missing\" $y_1$ and $y_0$. The $y$'s are pretty simple to deal with. The idea is to fill in $y_0$ with a drawn value whenever it is missing, doing the same for $y_1$. Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mata output:\n",
      "\n",
      ":     y0Hat = X*b0' + rnormal(rows(y),1,0,1)*exp(lnsd0)\n",
      "\n",
      ":     y1Hat = X*b1' + rnormal(rows(y),1,0,1)*exp(lnsd1)\n",
      "\n",
      ":     y1 = tr:*y + (1 :- tr):*y1Hat\n",
      "\n",
      ":     y0 = (1 :- tr):*y + tr:*y0Hat\n"
     ]
    }
   ],
   "source": [
    "%%stata --mata\n",
    "    y0Hat = X*b0' + rnormal(rows(y),1,0,1)*exp(lnsd0)\n",
    "    y1Hat = X*b1' + rnormal(rows(y),1,0,1)*exp(lnsd1)\n",
    "    y1 = tr:*y + (1 :- tr):*y1Hat\n",
    "    y0 = (1 :- tr):*y + tr:*y0Hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case for $z$ is a little more complicated, because it is latent and we have to draw a truncated random normal variable. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mata output:\n",
      "\n",
      ":     muz = W*e'\n",
      "\n",
      ":     et  = invnormstab( normal(-muz) + (1 :- normal(-muz)):*runiform(rows(muz),1) )\n",
      "\n",
      ":     ent = invnormstab( normal(-muz):*runiform(rows(muz),1) )\n",
      "\n",
      ":     z = muz + et:*tr + ent:*(1 :- tr)\n"
     ]
    }
   ],
   "source": [
    "%%stata --mata\n",
    "    muz = W*e'\n",
    "    et  = invnormstab( normal(-muz) + (1 :- normal(-muz)):*runiform(rows(muz),1) )\n",
    "    ent = invnormstab( normal(-muz):*runiform(rows(muz),1) )\n",
    "    z = muz + et:*tr + ent:*(1 :- tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing that makes everything a bit easier is if we compute deviations from means and keep track of these as we go along. We don't need to update these except for when draws or parameters change. Accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mata output:\n",
      "\n",
      ":     m0 = X*b0'\n",
      "\n",
      ":     m1 = X*b1'\n",
      "\n",
      ":     mt = W*e'\n",
      "\n",
      ":     ey1 = (y1 - m1)\n",
      "\n",
      ":     ey0 = (y0 - m0)\n",
      "\n",
      ":     et  = (z - mt)\n"
     ]
    }
   ],
   "source": [
    "%%stata --mata\n",
    "    m0 = X*b0'\n",
    "    m1 = X*b1'\n",
    "    mt = W*e'\n",
    "    ey1 = (y1 - m1)\n",
    "    ey0 = (y0 - m0)\n",
    "    et  = (z - mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make some placeholders for parameters, also put some prior distributions into action. We also calculate the symmetric inverse of $X'X$ and $W'W$, as these things never change so there is no great reason to keep calculating them as we run through the iterations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mata output:\n",
      "\n",
      ":     b1Hold        = b1\n",
      "\n",
      ":     b0Hold        = b0\n",
      "\n",
      ":     eHold         = e\n",
      "\n",
      ":     sy1Hold       = lnsd1\n",
      "\n",
      ":     sy0Hold       = lnsd0\n",
      "\n",
      ":     v10Hold       = v10\n",
      "\n",
      ":     v1tHold       = v1t\n",
      "\n",
      ":     v0tHold       = v0t\n",
      "\n",
      ":     \n",
      ":     XX = invsym(X'X)\n",
      "\n",
      ":     WW = invsym(W'W)\n"
     ]
    }
   ],
   "source": [
    "%%stata --mata\n",
    "    b1Hold        = b1\n",
    "    b0Hold        = b0\n",
    "    eHold         = e\n",
    "    sy1Hold       = lnsd1\n",
    "    sy0Hold       = lnsd0\n",
    "    v10Hold       = v10\n",
    "    v1tHold       = v1t\n",
    "    v0tHold       = v0t\n",
    "\n",
    "    draws = 100000\n",
    "    \n",
    "    XX = invsym(X'X)\n",
    "    WW = invsym(W'W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A typical draw of a latent variable\n",
    "\n",
    "While draws typically follow what we did above, it is helpful to just see how a typical draw and update goes for our $y_1$ variable. In this case, we have to compute the sub-matrices of $\\Sigma$, calculate conditional means, and then draw. Finally, we will update the error vector. The whole thing looks a little something like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mata output:\n",
      "\n",
      ": \n",
      ":     Sig12 = (v10, v1t)\n",
      "\n",
      ":     Sig22 = exp(lnsd0)^2, v0t \\ v0t, 1\n",
      "\n",
      ":     Sig22m1 = invsym(Sig22)\n",
      "\n",
      ":     CV = exp(lnsd1)^2 - Sig12*Sig22m1*Sig12'\n",
      "\n",
      ":     y1Hat = mc1 + rnormal(rows(y),1,0,1)*sqrt(CV)\n",
      "\n",
      ":     y1    = tr:*y + (1 :-tr):*y1Hat\n",
      "\n",
      ":     vb1 = exp(lnsd1)^2*XX\n",
      "\n",
      ":     b1 = mb1 + cholesky(vb1)*rnormal(cols(b1), 1, 0, 1)\n",
      "\n",
      ":     b1 = b1'\n",
      "\n",
      ":     ey1 = (y1 - m1)\n"
     ]
    }
   ],
   "source": [
    "%%stata --mata\n",
    "\n",
    "    Sig12 = (v10, v1t)\n",
    "    Sig22 = exp(lnsd0)^2, v0t \\ v0t, 1\n",
    "    Sig22m1 = invsym(Sig22)\n",
    "\n",
    "    CM = rowsum( (Sig12*Sig22m1):*(ey0, et) )\n",
    "    CV = exp(lnsd1)^2 - Sig12*Sig22m1*Sig12'\n",
    "\n",
    "    mc1   = m1 + CM\n",
    "    y1Hat = mc1 + rnormal(rows(y),1,0,1)*sqrt(CV)\n",
    "    y1    = tr:*y + (1 :-tr):*y1Hat\n",
    "\n",
    "    mb1 = XX*X'(y1 - CM)\n",
    "    vb1 = exp(lnsd1)^2*XX\n",
    "    b1 = mb1 + cholesky(vb1)*rnormal(cols(b1), 1, 0, 1)\n",
    "    b1 = b1'\n",
    "\n",
    "    m1 = X*b1'\n",
    "    ey1 = (y1 - m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typical MCMC - mwg draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mata output:\n",
      "\n",
      ":     prosd1 = 1\n",
      "\n",
      ":     gam = 1\n",
      "\n",
      ":     asta = .4\n",
      "\n",
      ":     Sigma    = exp(lnsd1)^2,   v10, v1t \\ v10, exp(lnsd0)^2, v0t \\ v1t, v0t, 1\n",
      "\n",
      ":     SigmaHat = exp(lnsd1Hat)^2,v10, v1t \\ v10, exp(lnsd0)^2, v0t \\ v1t, v0t, 1 \n",
      ">         valHat = ln_L((ey1, ey0, et), SigmaHat)\n",
      ">         alpha = min((exp(rat), 1))\n",
      ">             prosd1 = exp(gam*(alpha - asta))*prosd1\n",
      ">     else {\n",
      ">     }\n"
     ]
    }
   ],
   "source": [
    "%%stata --mata\n",
    "    prosd1 = 1\n",
    "    gam = 1\n",
    "    asta = .4\n",
    "\n",
    "    lnsd1Hat = lnsd1 + rnormal(1,1,0,1)*prosd1\n",
    "    Sigma    = exp(lnsd1)^2,   v10, v1t \\ v10, exp(lnsd0)^2, v0t \\ v1t, v0t, 1\n",
    "    SigmaHat = exp(lnsd1Hat)^2,v10, v1t \\ v10, exp(lnsd0)^2, v0t \\ v1t, v0t, 1 \n",
    "\n",
    "    if ( hasmissing(cholesky(SigmaHat)) == 0 ) {\n",
    "        val    = ln_L((ey1, ey0, et), Sigma)\n",
    "        valHat = ln_L((ey1, ey0, et), SigmaHat)\n",
    "        rat = valHat - val\n",
    "        alpha = min((exp(rat), 1))\n",
    "        if (runiform(1,1,0,1) < alpha) lnsd1 = lnsd1Hat\n",
    "            prosd1 = exp(gam*(alpha - asta))*prosd1\n",
    "    }\n",
    "    else {\n",
    "        prosd1 = exp(-asta*gam)*prosd1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
